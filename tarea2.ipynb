{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea #2\n",
    "\n",
    "En este documento se encuentran los contenidos requeridos en la Tarea corta #2 del curso Reconocimiento de Patrones\n",
    "\n",
    "\n",
    "## Dataset\n",
    "El dataset seleccionado es el de Vinos que viene incluido dentro de la biblioteca ScikitLearn, este clasifica vinos en tres diferentes clases, basandose en 13 atributos entre los que se encuentran los siguientes\n",
    "* Alcohol\n",
    "* Magnesio\n",
    "* intensidad de color\n",
    "\n",
    "Este dataset es de clasificación, por lo tanto se utilizaran los métodos vistos en clases como kNN, regresión logistica, el método de Naive Bayes, random forest, y además se incluirá un quinto método que no se vio en clases que es la clasificación por el método de Descenso de gradiente estocástico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente bloque de código se importará el set de datos que se utilizará y se le hará un breve análisis para ver sus clases y propiedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0', 'class_1', 'class_2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wines = load_wine()\n",
    "print(list(wines.target_names))\n",
    "#Se puede observar que las clases de vino estan representadas por números de 0 al 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos\n",
    "\n",
    "***Cuatro de los algoritmos son tomados del material visto en clase y se adaptaron para ser utilizados con el dataset seleccionado, el primer algoritmo (Stochastic Gradient Descent) se implementó como parte de los requerimientos.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VERIFICACIÓN\n",
    "\n",
    "Para la verificación de los modelos entrenados se utiliza el mecanismo de validación cruzada que separa el set de datos en conjuntos más pequeños y hace varias pruebas para al final calcular un promedio de estos, esto brinda una visión distinta de los resultados ya que no estaria utilizando los mismo datos para entrenar y probar.\n",
    "\n",
    "El método utilizado es el siguiente:\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "\n",
    "Se utiliza un cv = 5 que es el que viene por defecto, este valor especifica la estrategia de como se va a partir el set de datos para hacer la validación cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Este es el método elegido para realizar la clasificación de los vinos en 3 distintas clases, se eligió este método ya que se investigaron varios métodos y este es uno de los métodos simples pero muy eficientes, además es un método bastante sencillo de implementar, y al estar trabajando con set de datos relativamente sencillos funciona de manera correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.634\n",
      "0.57 accuracy with a standard deviation of 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "wines = load_wine()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pre = clf.predict(X_train)\n",
    "print(\"Training set score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    " **Balanced accuracy score**\n",
    " Este es el promedio obtenido del recall de cada clase del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0, 37],\n",
       "       [ 0,  0, 57],\n",
       "       [ 0,  0, 40]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train, y_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matriz de confusión**\n",
    "Crea una matriz de nxn donde n es la cantidad de clases que tiene el dataset, esta hace una matriz con los resultados indicando cuantas predicciones se realizaron correctamente y cuantas fueron falsos positivos, entre mayor sea la diagonal mayor será la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 12,  0],\n",
       "       [ 0, 57,  0],\n",
       "       [ 0, 40,  0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## K nearest neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.739\n",
      "Test set score: 0.750\n",
      "0.70 accuracy with a standard deviation of 0.03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0, 37],\n",
       "       [ 0,  0, 57],\n",
       "       [ 0,  0, 40]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "wines = load_wine()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neighbors = 15\n",
    "clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf.fit(X_train, y_train)\n",
    "training_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(training_accuracy))\n",
    "print(\"Test set score: {:.3f}\".format(test_accuracy))\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "confusion_matrix(y_train, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.992\n",
      "Test set score: 0.966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.64616402, 0.63029101, 0.65674603, 0.70952381, 0.75555556])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, test_size=0.33, random_state=6)\n",
    "logreg = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de naive Bayes con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.972\n",
      "Test set score: 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70833333, 0.7037037 , 0.75378788, 0.69781145, 0.6797138 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "wines = load_wine()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, test_size=0.2, random_state=42)\n",
    "\n",
    "nbg = GaussianNB().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nbg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(nbg.score(X_test, y_test)))\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos como en el casos anteriores, para más detalles sobre *Random Forest* referirse a: http://scikit-learn.org/stable/modules/ensemble.html#forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.933\n",
      "Test set score: 0.847\n",
      "Training set score: 1.000\n",
      "Test set score: 1.000\n",
      "0.69 accuracy with a standard deviation of 0.06\n"
     ]
    }
   ],
   "source": [
    "wines = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, test_size=0.33)\n",
    "rf = RandomForestClassifier(n_estimators=1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(rf.score(X_test, y_test)))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(rf.score(X_test, y_test)))\n",
    "scores = cross_val_score(clf, X_train,y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
